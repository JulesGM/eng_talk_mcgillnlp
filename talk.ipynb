{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to make things fast!\n",
    "\n",
    "- Basics of shared-memory and per-process parallelism\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- How to use that in python\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- Multiprocessing pools\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- Multiprocess Queues & Pipes, which are the recommended way to do parallelism in python\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- The Global Interpreter Lock and why shared memory parallelism is limited in Python\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- Floating point representations, what they really mean and how to think about them, eg Float16 vs bfloat16 vs float32\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- How to do multi-node training on the Mila Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concurrency\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "Concurrency is the idea of running multiple chains of program execution in parallel. Concurrency allows for \n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- Faster execution (in the context of parallel computing)\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- Better resource utilization (eg., not waste time waiting for things that are slow)\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "The idea is that you split your program in multiple lines of execution that work at the time.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "### Threads\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "In *threads*, the memory of the different lines of execution is shared.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "As such, it is easy for threads to work on shared resources and shared variables and objects, \n",
    "and there is no need to copy data between threads.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "A disadvantage of threads is that it's very easy to not be careful and have them interfere with each other.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "### Processes\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "In *processes*, the memory of the different lines of execution is not shared. \n",
    "\n",
    "&nbsp;\n",
    "\n",
    "The memory is completely separate. The only way to communicate between processes is to use\n",
    "special objects called *queues* and *pipes*. \n",
    "\n",
    "&nbsp;\n",
    "\n",
    "It is costly to communicate between processes.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "### Threads in Python are Limited: The Global Interpreter Lock\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "Python has false multi-threading. In order to make memory management (garbage collection) \n",
    "fast enough for the single-thread case, they made it so the interpreter can only run one \"instruction\" at a time.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "This is called the Global Interpreter Lock (GIL). There is literally a lock (something stopping other threads from executing) that is held by the interpreter\n",
    "when it is running a line of code. This heavily li\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n"
     ]
    }
   ],
   "source": [
    "# Example of Threading / Shared memory Parallelism\n",
    "\n",
    "%reset -f\n",
    "import threading\n",
    "\n",
    "shared_thing_lock = threading.Lock()\n",
    "shared_thing = []\n",
    "\n",
    "def increment(th_id, shared_thing):\n",
    "    with shared_thing_lock:\n",
    "        shared_thing.append(th_id)\n",
    "\n",
    "threads = [threading.Thread(target=increment, args=(i, shared_thing)) for i in range(100)]\n",
    "[thread.start() for thread in threads]\n",
    "\n",
    "print(shared_thing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Example of Isolated Memory Parallelism / Multiprocessing\n",
    "\n",
    "%reset -f\n",
    "import multiprocess\n",
    "\n",
    "shared_thing_lock = multiprocess.Lock()\n",
    "shared_thing = []\n",
    "\n",
    "def increment(proc_id, shared_thing):\n",
    "    with shared_thing_lock:\n",
    "        shared_thing.append(proc_id)\n",
    "\n",
    "processes = [multiprocess.Process(target=increment, args=(i, shared_thing)) for i in range(100)]\n",
    "[processe.start() for processe in processes]\n",
    "\n",
    "print(shared_thing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threading and Processing pools\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "Threading and processing pools are a way to make parallelism easier in python.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "They also reduce the overhead of creating and destroying processes and threads by reusing them.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "They also make sure the exceptions propagate to the main process in the case of multiprocessing.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "In the case of multiprocessing, they also return the results without having to use queues explicitely.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "### Multiprocessing pools\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "```python\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "\n",
    "num_processes = os.cpu_count()\n",
    "with mp.Pool(num_processes) as pool:\n",
    "    results = pool.map(func, iterable)\n",
    "\n",
    "print(results)\n",
    "```\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "### Multithreading pools\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "```python\n",
    "import multiprocessing.dummy as mp\n",
    "import os\n",
    "\n",
    "num_threads = os.cpu_count()\n",
    "with mp.Pool(num_threads) as pool:\n",
    "    results = pool.map(func, iterable)\n",
    "\n",
    "print(results)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just once:  0.07 seconds\n",
      "10 * duration_once = 0.65 seconds\n",
      "duration_10x_proc  = 0.24 seconds\n",
      "Speedup of  2.76 times\n"
     ]
    }
   ],
   "source": [
    "# Demonstration of multiprocessing Pools:\n",
    "\n",
    "%reset -f\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import multiprocess\n",
    "\n",
    "\n",
    "# Function to be parallelized\n",
    "def expensive_thing(proc_id):\n",
    "    return math.factorial(50000) + proc_id\n",
    "\n",
    "\n",
    "# Call the function once as a baseline\n",
    "start = time.time()\n",
    "expensive_thing(0)\n",
    "duration_once = time.time() - start\n",
    "n_processes = 10\n",
    "\n",
    "\n",
    "# Call the function in parallel\n",
    "with multiprocess.Pool(n_processes) as pool:\n",
    "    start = time.time()\n",
    "    results = pool.map(expensive_thing, range(n_processes))\n",
    "    duration_10x_proc = time.time() - start\n",
    "\n",
    "\n",
    "# Print the results\n",
    "print(f\"Just once: {duration_once: 0.2f} seconds\")\n",
    "print(f\"{10 * duration_once = :0.2f} seconds\")\n",
    "print(f\"{duration_10x_proc  = :0.2f} seconds\")\n",
    "print(f\"Speedup of {(10 * duration_once) / duration_10x_proc : 0.2f} times\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10x Duration once: 0.66534 seconds\n",
      "Duration 10 threads: 0.77780 seconds\n",
      "Speedup of  0.86 times\n"
     ]
    }
   ],
   "source": [
    "# Communication without a Pool\n",
    "%reset -f\n",
    "import os\n",
    "import threading\n",
    "import time\n",
    "import queue\n",
    "import math\n",
    "\n",
    "# The queue to communicate the results\n",
    "results = queue.Queue()\n",
    "\n",
    "\n",
    "# The expensive function to be parallelized\n",
    "def expensive_thing(th_id):\n",
    "    results.put(math.factorial(50000) + th_id)\n",
    "\n",
    "\n",
    "# Call the function once as a baseline\n",
    "start = time.perf_counter()\n",
    "expensive_thing(0)\n",
    "duration_once = time.perf_counter() - start\n",
    "\n",
    "\n",
    "# Create the threads\n",
    "n_threads = 10\n",
    "threads = [threading.Thread(target=expensive_thing, args=(i,)) for i in range(n_threads)]\n",
    "\n",
    "\n",
    "# Start the threads\n",
    "start = time.perf_counter()\n",
    "[thread.start() for thread in threads]\n",
    "\n",
    "\n",
    "# Wait for the threads to finish\n",
    "[thread.join() for thread in threads]\n",
    "\n",
    "\n",
    "# Get the results\n",
    "results = [results.get() for _ in range(n_threads)]\n",
    "duration_threading = time.perf_counter() - start\n",
    "\n",
    "\n",
    "# Print the results\n",
    "print(f\"10x Duration once: {10 * duration_once:0.5f} seconds\")\n",
    "print(f\"Duration 10 threads: {duration_threading:0.5f} seconds\")\n",
    "print(f\"Speedup of {10 * duration_once / duration_threading: 0.2} times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 = 10\n",
      "10x Duration once: 0.83267 seconds\n",
      "Duration 10 threads: 0.46481 seconds\n",
      "Speedup of  1.8 times\n"
     ]
    }
   ],
   "source": [
    "# Same as above, but with a Pool\n",
    "%reset -f\n",
    "import os\n",
    "import threading\n",
    "import time\n",
    "import queue\n",
    "import math\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "\n",
    "# Expensive function to be parallelized\n",
    "def expensive_thing(proc_id):\n",
    "    return math.factorial(50000) + proc_id\n",
    "\n",
    "\n",
    "# Call the function once as a baseline\n",
    "start = time.perf_counter()\n",
    "expensive_thing(0)\n",
    "duration_once = time.perf_counter() - start\n",
    "\n",
    "\n",
    "print(f\"{10 = }\")\n",
    "\n",
    "\n",
    "# Create the pool & call the function in parallel\n",
    "with ThreadPoolExecutor(10) as pool:\n",
    "    start = time.perf_counter()\n",
    "    results = pool.map(expensive_thing, range(os.cpu_count()))\n",
    "    duration_pool = time.perf_counter() - start\n",
    "\n",
    "\n",
    "# Print the results\n",
    "print(f\"10x Duration once: {10 * duration_once:0.5f} seconds\")\n",
    "print(f\"Duration 10 threads: {duration_pool:0.5f} seconds\")\n",
    "print(f\"Speedup of {10 * duration_once / duration_pool: 0.2} times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running install\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "writing run.egg-info/PKG-INFO\n",
      "writing dependency_links to run.egg-info/dependency_links.txt\n",
      "writing top-level names to run.egg-info/top_level.txt\n",
      "reading manifest file 'run.egg-info/SOURCES.txt'\n",
      "writing manifest file 'run.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.macosx-10.9-x86_64/egg\n",
      "running install_lib\n",
      "running build_ext\n",
      "building 'run' extension\n",
      "gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/Users/jules/.anaconda3/include -arch x86_64 -I/Users/jules/.anaconda3/include -arch x86_64 -I/Users/jules/.anaconda3/include/python3.8 -c /Users/jules/Documents/Work/talk/.copperhead_cache/run/run_block.cpp -o build/temp.macosx-10.9-x86_64-3.8/Users/jules/Documents/Work/talk/.copperhead_cache/run/run_block.o\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cc1plus: warning: command-line option '-Wstrict-prototypes' is valid for C/ObjC but not for C++\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g++ -bundle -undefined dynamic_lookup -L/Users/jules/.anaconda3/lib -arch x86_64 -L/Users/jules/.anaconda3/lib -arch x86_64 -arch x86_64 build/temp.macosx-10.9-x86_64-3.8/Users/jules/Documents/Work/talk/.copperhead_cache/run/run_block.o -o build/lib.macosx-10.9-x86_64-3.8/run.cpython-38-darwin.so\n",
      "creating build/bdist.macosx-10.9-x86_64/egg\n",
      "copying build/lib.macosx-10.9-x86_64-3.8/run.cpython-38-darwin.so -> build/bdist.macosx-10.9-x86_64/egg\n",
      "creating stub loader for run.cpython-38-darwin.so\n",
      "byte-compiling build/bdist.macosx-10.9-x86_64/egg/run.py to run.cpython-38.pyc\n",
      "creating build/bdist.macosx-10.9-x86_64/egg/EGG-INFO\n",
      "copying run.egg-info/PKG-INFO -> build/bdist.macosx-10.9-x86_64/egg/EGG-INFO\n",
      "copying run.egg-info/SOURCES.txt -> build/bdist.macosx-10.9-x86_64/egg/EGG-INFO\n",
      "copying run.egg-info/dependency_links.txt -> build/bdist.macosx-10.9-x86_64/egg/EGG-INFO\n",
      "copying run.egg-info/top_level.txt -> build/bdist.macosx-10.9-x86_64/egg/EGG-INFO\n",
      "writing build/bdist.macosx-10.9-x86_64/egg/EGG-INFO/native_libs.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ld: warning: dylib (/usr/local/Cellar/gcc/12.2.0/lib/gcc/current/libstdc++.dylib) was built for newer macOS version (11.0) than being linked (10.9)\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "__pycache__.run.cpython-38: module references __file__\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating 'dist/run-0.0.0-py3.8-macosx-10.9-x86_64.egg' and adding 'build/bdist.macosx-10.9-x86_64/egg' to it\n",
      "removing 'build/bdist.macosx-10.9-x86_64/egg' (and everything under it)\n",
      "Processing run-0.0.0-py3.8-macosx-10.9-x86_64.egg\n",
      "removing '/Users/jules/Documents/Work/talk/.copperhead_cache/run/run-0.0.0-py3.8-macosx-10.9-x86_64.egg' (and everything under it)\n",
      "creating /Users/jules/Documents/Work/talk/.copperhead_cache/run/run-0.0.0-py3.8-macosx-10.9-x86_64.egg\n",
      "Extracting run-0.0.0-py3.8-macosx-10.9-x86_64.egg to /Users/jules/Documents/Work/talk/.copperhead_cache/run\n",
      "run 0.0.0 is already the active version in easy-install.pth\n",
      "\n",
      "Installed /Users/jules/Documents/Work/talk/.copperhead_cache/run/run-0.0.0-py3.8-macosx-10.9-x86_64.egg\n",
      "Processing dependencies for run==0.0.0\n",
      "Finished processing dependencies for run==0.0.0\n",
      "[4457177.0]\n",
      "\n",
      "\n",
      "\n",
      "10 * duration single: 15.98842 seconds\n",
      "Duration 10 threads: 7.10033 seconds\n",
      "Speedup of  2.252 times\n"
     ]
    }
   ],
   "source": [
    "# Example of Threads In \"Regular\" Languages\n",
    "\n",
    "%reset -f\n",
    "import os\n",
    "import time\n",
    "\n",
    "import copperhead as cpp\n",
    "\n",
    "\n",
    "code = \"\"\"\n",
    "\n",
    "#include <iostream>\n",
    "#include <thread>\n",
    "#include <vector>\n",
    "#include <cmath>\n",
    "#include <random>\n",
    "using namespace std;\n",
    "\n",
    "// Function to be parallelized\n",
    "void busy_work(int n, double* result) {\n",
    "    *result = 1;\n",
    "    for (int i = 1; i <= n; i++) {\n",
    "        *result = fmod(*result + rand(), 10000000);\n",
    "    }\n",
    "}\n",
    "\n",
    "// Start the threads from inside C++\n",
    "vector<double> run(int n_threads, int fn_arg) {\n",
    "\n",
    "    // This will hold the results\n",
    "    vector<double> results(n_threads, 0);\n",
    "    \n",
    "    // Create pointers for the threads.\n",
    "    std::thread* threads[n_threads];\n",
    "\n",
    "    // Create and start each thread.\n",
    "    // Each thread will write its result to the corresponding element of `results`.\n",
    "    for (int i = 0; i < n_threads; i++) {\n",
    "        threads[i] = new std::thread(busy_work, fn_arg, &results[i]);\n",
    "    }\n",
    "\n",
    "    // Wait for the threads to finish\n",
    "    for (int i = 0; i < n_threads; i++) {\n",
    "        threads[i]->join();\n",
    "    }\n",
    "\n",
    "    return results;\n",
    "}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Compile the code\n",
    "run_threads = cpp.generate(\"run\", \"std::vector<double> (int, int)\", code, rebuild=True)\n",
    "\n",
    "\n",
    "# Call the function once as a baseline\n",
    "start = time.perf_counter()\n",
    "once = run_threads(1, 50000000)\n",
    "duration_single = time.perf_counter() - start\n",
    "print(once)\n",
    "\n",
    "\n",
    "# Call the function in parallel\n",
    "start = time.perf_counter()\n",
    "outputs = run_threads(os.cpu_count(), 50000000)\n",
    "duration_threading = time.perf_counter() - start\n",
    "\n",
    "\n",
    "# Print the results\n",
    "print(\"\\n\\n\")\n",
    "print(f\"10 * duration single: {10 * duration_single:0.5f} seconds\")\n",
    "print(f\"Duration {10} threads: {duration_threading:0.5f} seconds\")\n",
    "print(f\"Speedup of {(10 * duration_single) / duration_threading: 0.3f} times\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important Points to Remember:\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "### Processes\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- Multiprocessing is the recommended way to do parallelism in Python. Use it. It's fast and easy with `multiprocessing.Pool` or `concurrent.futures.ProcessPoolExecutor`.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- Communication between processes is costly. Everything needs to be pickled, sent through a pipe, then unpickled.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- If you need communication between processes, read up on `multiprocessing.Manager()` and `multiprocessing.Queue()`.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "### Queues\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- *If you are doing things that are not CPU-bound, you should use threads instead of processes.*\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- For example, if you are reading heavy files. use `multiprocessing.dummy.Pool` or `concurrent.futures.ThreadPoolExecutor`.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- Also you are downloading multiple things at the same time, use threads.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- If you need to communicate between threads, use `queue.Queue` or `queue.Pipe`. They are thread-safe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Floating Point Numbers & Representations\n",
    "\n",
    "\n",
    "### Why this is important:\n",
    "\n",
    "Torch and Pytorch Lightning (through torch) allow the use of different floating point representations. \n",
    "\n",
    "&nbsp;\n",
    "\n",
    "These representations allow very large speedups, but there is a tradeoff in precision.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "Here are illustrations of the differences in computation power as a function of precision:\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "![why_precision](why_precision.png)\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "Understanding the meaning of these representations is important to understand the tradeoff.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "\n",
    "### How to use mixed precision training in Pytorch and Pytorch Lightning:\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "\n",
    "First, how to use lower precision. With Pytorch Lightning, it's as simple as setting `precision=16` or `precision=bfloat16` in the trainer:\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "\n",
    "![precision](precision.png)\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "\n",
    "For further information, see https://pytorch-lightning.readthedocs.io/en/latest/guides/speed.html#mixed-precision-16-bit-training\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "You can do something similar in raw Pytorch of course, but it's slightly more complicated.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "![precision2](precision2.png)\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "For further information, see https://pytorch.org/docs/stable/amp.html#autocasting\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "\n",
    "### What are floating point numbers & how do they work ?\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "Floating point numbers are what CPUs and GPUs use to represent numbers.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "They are scary, but they are in fact identical scientific notation, except in base 2.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "Assuming we have 5 significant digits:\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "Scientific notation:   - 3.5484 x 10^25\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "This number has three parts: the sign, the mantissa, and the exponent.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "Here, the sign is -1.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "The mantissa is 3.5484. It's a number between 1 and 10 representing the signifigant digits.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "The exponent is 25.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "### Floating point numbers work the same way, except in base 2:\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- The sign is either 0 or 1.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- The mantissa is an integer in base 2, represented by a string of bits. \n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- The exponent is an integer in base 2, represented by a string of bits, and the number that is exponentiated is 2. It's value is always between 1 and 2, just as the mantissa is always between 1 and 10 in scientific notation.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- This is all you really need to know, the rest are details to get the details right.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "### Technical details:\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- We always divide the mantissa by its maximum int value, then add 1. This is to constrain it to its role of representing a number between 1 and 2. You can also guess the number of significant digits from this.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- We substract half of the number of bits of the exponent from the exponent, making it so that the exponent is always between -2^(number_of_bits_of_exponent - 1) and 2^(number_of_bits_of_exponent - 1). This representation apparently makes comparison betweeb floats faster.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "### Important point:\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- In *float16*, there are 5 bits for the exponent, and 10 bits for the mantissa. This means that the exponent is between -16 and 15 \n",
    "\n",
    "&nbsp;\n",
    "\n",
    "![float16](float16.png)\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- *float32* has 8 bits of exponent, and 23 bits of mantissa. This means that the exponent is between -128 and 127. \n",
    "\n",
    "&nbsp;\n",
    "\n",
    "![float32](single.png)\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- *bfloat16* also has 16 bits, but it has 8 bits of exponent like the float32, and 7 bits of mantissa. This means that the exponent is also between -128 and 127. \n",
    "\n",
    "&nbsp;\n",
    "\n",
    "![bfloat16](bfloat16.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import torch\n",
    "import sys\n",
    "import bitstring\n",
    "import math\n",
    "\n",
    "def get_raw_bits(tensor, num_bits):\n",
    "    if num_bits == 16:\n",
    "        tensor = tensor.view(torch.int16)\n",
    "    elif num_bits == 32:\n",
    "        tensor = tensor.view(torch.int32)\n",
    "    elif num_bits == 64:\n",
    "        tensor = tensor.view(torch.int64)\n",
    "    else:\n",
    "        raise ValueError(\"num_bits must be 16, 32, or 64\")\n",
    "    \n",
    "    array = bitstring.BitArray(bytes=tensor.numpy().tobytes())\n",
    "    array.byteswap()\n",
    "    return array.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rich\n",
    "import rich.table\n",
    "console = rich.console.Console(width=240)\n",
    "\n",
    "def to_int(bits):\n",
    "    return sum([int(bit) * 2 ** (i) for i, bit in enumerate(bits[::-1])])\n",
    "\n",
    "def float32(bits):\n",
    "    sign_bit = int(bits[0])\n",
    "    exponent = to_int(bits[1:9])\n",
    "    mantissa = to_int(bits[9:32])\n",
    "\n",
    "\n",
    "    # Compute Sign\n",
    "    sign = (-1) ** sign_bit\n",
    "\n",
    "\n",
    "    # Compute the exponentiation factor\n",
    "    resulting_power = exponent - 127\n",
    "    exponentiation_factor = 2 ** resulting_power\n",
    "\n",
    "\n",
    "    # Compute the significant factor\n",
    "    mantissa_multiplier = 1 + mantissa / 2 ** 23   # 23 is the number of bits in the mantissa. \n",
    "\n",
    "\n",
    "\n",
    "    # Put things together\n",
    "    result = sign * exponentiation_factor * mantissa_multiplier\n",
    "    result_direct = (-1) ** sign_bit * 2 ** (exponent - 127) * (1 + mantissa / 2 ** 23)\n",
    "    assert result == result_direct\n",
    "\n",
    "\n",
    "    # Print the details\n",
    "    table = rich.table.Table(\"Descript\",   \"Eqn\",                                                       \"Value\", title=\"Float32\")\n",
    "    table.add_row(\"Sign bit\",              \"bits[0]\",                                                   str(sign_bit),            end_section=True)\n",
    "    table.add_row(\"Sign\",                  \"(-1) ** (bits[0])\",                                         str(sign))\n",
    "    table.add_row(\"Mantissa bits\",         \"bits[9:32]\",                                                str(bits[9:32]))\n",
    "    table.add_row(\"Mantissa\",              \"to_int(bits[9:32])\",                                        str(mantissa),            )\n",
    "    table.add_row(\"Mantissa Multiplier\",   \"1 + mantissa / 2 ** 23\",                                    str(mantissa_multiplier), end_section=True)\n",
    "    table.add_row(\"Exponent bits\",         \"bits[1:9]\",                                                 str(bits[1:9]))\n",
    "    table.add_row(\"Exponent\",              \"to_int(bits[1:9])\",                                         str(exponent))\n",
    "    table.add_row(\"Exponentiation factor\", \"2 ** resulting_power\",                                      str(exponentiation_factor))\n",
    "    table.add_row(\"Resulting Power\",       \"exponent - 127\",                                            str(resulting_power),     end_section=True)\n",
    "    table.add_row(\"Result\",                f\"{sign} * {mantissa_multiplier} * {exponentiation_factor}\", f\"[bold blue]{result}\")\n",
    "    console.print(table)\n",
    "    print()\n",
    "    return result\n",
    "\n",
    "def float16(bits):\n",
    "    sign_bit = int(bits[0])\n",
    "    exponent = to_int(bits[1:6])\n",
    "    mantissa = to_int(bits[6:16])\n",
    "\n",
    "\n",
    "\n",
    "    # Compute Sign\n",
    "    sign = (-1) ** sign_bit\n",
    "\n",
    "\n",
    "\n",
    "    # Compute the exponentiation factor\n",
    "    resulting_power = exponent - 15\n",
    "    exponentiation_factor = 2 ** resulting_power\n",
    "\n",
    "\n",
    "\n",
    "    # Compute the significant factor\n",
    "    mantissa_multiplier = 1 + mantissa / 2 ** 10\n",
    "\n",
    "\n",
    "    # Put things together\n",
    "    result = sign * exponentiation_factor * mantissa_multiplier\n",
    "    result_direct = (-1) ** sign_bit * 2 ** (exponent - 15) * (1 + mantissa / 2 ** 10)\n",
    "\n",
    "\n",
    "    # Print the details\n",
    "    table = rich.table.Table(\"Descript\",   \"Eqn\",                                                       \"Value\", title=\"Float16\")\n",
    "    table.add_row(\"Sign bit\",              \"bits[0]\",                                                   str(sign_bit),              end_section=True)\n",
    "    table.add_row(\"Sign\",                  \"(-1) ** to_int(bits[0])\",                                   str(sign),                  end_section=True)\n",
    "    table.add_row(\"Mantissa bits\",         \"bits[6:16]\",                                                str(bits[6:16]))\n",
    "    table.add_row(\"Mantissa\",              \"to_int(bits[6:16])\",                                        str(mantissa))\n",
    "    table.add_row(\"Mantissa Factor\",       \"1 + mantissa / 2 ** 10\",                                    str(mantissa_multiplier),   end_section=True)\n",
    "    table.add_row(\"Exponent bits\",         \"bits[1:6]\",                                                 str(bits[1:6]))\n",
    "    table.add_row(\"Exponent\",              \"to_int(bits[1:6])\",                                         str(exponent))\n",
    "    table.add_row(\"Resulting Power\",       \"exponent - 15\",                                             str(resulting_power),)\n",
    "    table.add_row(\"Exponent Factor\",       \"2 ** resulting_power\",                                      str(exponentiation_factor), end_section=True)\n",
    "    table.add_row(\"Result\",                f\"{sign} * {mantissa_multiplier} * {exponentiation_factor}\", f\"[bold blue]{result}\")\n",
    "    console.print(table)\n",
    "    print()\n",
    "\n",
    "    return result\n",
    "\n",
    "def bfloat16(bits):\n",
    "    sign_bits = int(bits[0])\n",
    "    exponent = to_int(bits[1:9])\n",
    "    mantissa = to_int(bits[9:16])\n",
    "\n",
    "\n",
    "    # Compute Sign\n",
    "    sign = (-1) ** sign_bits\n",
    "\n",
    "\n",
    "    # Compute the exponentiation factor\n",
    "    resulting_power = exponent - 127\n",
    "    exponent_factor = 2 ** resulting_power\n",
    "\n",
    "\n",
    "    # Compute the significant factor\n",
    "    mantissa_multiplier = 1 + mantissa / 2 ** 7\n",
    "\n",
    "\n",
    "    # Put things together\n",
    "    result = sign * exponent_factor * mantissa_multiplier\n",
    "    result_direct = (-1) ** sign_bits * 2 ** (exponent - 127) * (1 + mantissa / 2 ** 7)\n",
    "\n",
    "\n",
    "\n",
    "    # Print the details\n",
    "    table = rich.table.Table(\"Descript\",   \"Eqn\",                                                    \"Value\", title=\"BFloat16\")\n",
    "    table.add_row(\"Sign bits\",             \"bits[0]\",                                                str(bits[0]), end_section=True)\n",
    "    table.add_row(\"Sign\",                  \"(-1) ** to_int(bits[0])\",                                str(sign), end_section=True)\n",
    "    table.add_row(\"Mantissa bits\",         \"bits[9:16]\",                                             str(bits[9:16]),)\n",
    "    table.add_row(\"Mantissa\",              \"to_int(bits[9:16])\",                                     str(mantissa),)\n",
    "    table.add_row(\"Mantissa Multiplier\",   \"1 + mantissa / 2 ** 7\",                                  str(mantissa_multiplier), end_section=True)\n",
    "    table.add_row(\"Exponent bits\",         \"bits[1:9]\",                                              str(bits[1:9]),)\n",
    "    table.add_row(\"Exponent\",              \"to_int(bits[1:9])\",                                      str(exponent))\n",
    "    table.add_row(\"Resulting Power\",       \"exponent - 127\",                                         str(resulting_power))\n",
    "    table.add_row(\"Exponent Factor\",       \"2 ** resulting_power\",                                   str(exponent_factor), end_section=True)\n",
    "    table.add_row(\"Result\",                f\"{sign} * {mantissa_multiplier} * {exponent_factor}\",    f\"[bold blue]{result}\")\n",
    "    console.print(table)\n",
    "    print()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                    Float32                                     </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Descript              </span>┃<span style=\"font-weight: bold\"> Eqn                        </span>┃<span style=\"font-weight: bold\"> Value                   </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Sign bit              │ bits[0]                    │ 0                       │\n",
       "├───────────────────────┼────────────────────────────┼─────────────────────────┤\n",
       "│ Sign                  │ (-1) ** (bits[0])          │ 1                       │\n",
       "│ Mantissa bits         │ bits[9:32]                 │ 01011011111100001010100 │\n",
       "│ Mantissa              │ to_int(bits[9:32])         │ 3012692                 │\n",
       "│ Mantissa Multiplier   │ 1 + mantissa / 2 ** 23     │ 1.3591408729553223      │\n",
       "├───────────────────────┼────────────────────────────┼─────────────────────────┤\n",
       "│ Exponent bits         │ bits[1:9]                  │ 10000000                │\n",
       "│ Exponent              │ to_int(bits[1:9])          │ 128                     │\n",
       "│ Exponentiation factor │ 2 ** resulting_power       │ 2                       │\n",
       "│ Resulting Power       │ exponent - 127             │ 1                       │\n",
       "├───────────────────────┼────────────────────────────┼─────────────────────────┤\n",
       "│ Result                │ 1 * 1.3591408729553223 * 2 │ <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">2.7182817459106445</span>      │\n",
       "└───────────────────────┴────────────────────────────┴─────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                    Float32                                     \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mDescript             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mEqn                       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                  \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Sign bit              │ bits[0]                    │ 0                       │\n",
       "├───────────────────────┼────────────────────────────┼─────────────────────────┤\n",
       "│ Sign                  │ (-1) ** (bits[0])          │ 1                       │\n",
       "│ Mantissa bits         │ bits[9:32]                 │ 01011011111100001010100 │\n",
       "│ Mantissa              │ to_int(bits[9:32])         │ 3012692                 │\n",
       "│ Mantissa Multiplier   │ 1 + mantissa / 2 ** 23     │ 1.3591408729553223      │\n",
       "├───────────────────────┼────────────────────────────┼─────────────────────────┤\n",
       "│ Exponent bits         │ bits[1:9]                  │ 10000000                │\n",
       "│ Exponent              │ to_int(bits[1:9])          │ 128                     │\n",
       "│ Exponentiation factor │ 2 ** resulting_power       │ 2                       │\n",
       "│ Resulting Power       │ exponent - 127             │ 1                       │\n",
       "├───────────────────────┼────────────────────────────┼─────────────────────────┤\n",
       "│ Result                │ 1 * 1.3591408729553223 * 2 │ \u001b[1;34m2.7182817459106445\u001b[0m      │\n",
       "└───────────────────────┴────────────────────────────┴─────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                          BFloat16                          </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Descript            </span>┃<span style=\"font-weight: bold\"> Eqn                     </span>┃<span style=\"font-weight: bold\"> Value    </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━┩\n",
       "│ Sign bits           │ bits[0]                 │ 0        │\n",
       "├─────────────────────┼─────────────────────────┼──────────┤\n",
       "│ Sign                │ (-1) ** to_int(bits[0]) │ 1        │\n",
       "├─────────────────────┼─────────────────────────┼──────────┤\n",
       "│ Mantissa bits       │ bits[9:16]              │ 0101110  │\n",
       "│ Mantissa            │ to_int(bits[9:16])      │ 46       │\n",
       "│ Mantissa Multiplier │ 1 + mantissa / 2 ** 7   │ 1.359375 │\n",
       "├─────────────────────┼─────────────────────────┼──────────┤\n",
       "│ Exponent bits       │ bits[1:9]               │ 10000000 │\n",
       "│ Exponent            │ to_int(bits[1:9])       │ 128      │\n",
       "│ Resulting Power     │ exponent - 127          │ 1        │\n",
       "│ Exponent Factor     │ 2 ** resulting_power    │ 2        │\n",
       "├─────────────────────┼─────────────────────────┼──────────┤\n",
       "│ Result              │ 1 * 1.359375 * 2        │ <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">2.71875</span>  │\n",
       "└─────────────────────┴─────────────────────────┴──────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                          BFloat16                          \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mDescript           \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mEqn                    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue   \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━┩\n",
       "│ Sign bits           │ bits[0]                 │ 0        │\n",
       "├─────────────────────┼─────────────────────────┼──────────┤\n",
       "│ Sign                │ (-1) ** to_int(bits[0]) │ 1        │\n",
       "├─────────────────────┼─────────────────────────┼──────────┤\n",
       "│ Mantissa bits       │ bits[9:16]              │ 0101110  │\n",
       "│ Mantissa            │ to_int(bits[9:16])      │ 46       │\n",
       "│ Mantissa Multiplier │ 1 + mantissa / 2 ** 7   │ 1.359375 │\n",
       "├─────────────────────┼─────────────────────────┼──────────┤\n",
       "│ Exponent bits       │ bits[1:9]               │ 10000000 │\n",
       "│ Exponent            │ to_int(bits[1:9])       │ 128      │\n",
       "│ Resulting Power     │ exponent - 127          │ 1        │\n",
       "│ Exponent Factor     │ 2 ** resulting_power    │ 2        │\n",
       "├─────────────────────┼─────────────────────────┼──────────┤\n",
       "│ Result              │ 1 * 1.359375 * 2        │ \u001b[1;34m2.71875\u001b[0m  │\n",
       "└─────────────────────┴─────────────────────────┴──────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                         Float16                          </span>\n",
       "┏━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Descript        </span>┃<span style=\"font-weight: bold\"> Eqn                     </span>┃<span style=\"font-weight: bold\"> Value      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ Sign bit        │ bits[0]                 │ 0          │\n",
       "├─────────────────┼─────────────────────────┼────────────┤\n",
       "│ Sign            │ (-1) ** to_int(bits[0]) │ 1          │\n",
       "├─────────────────┼─────────────────────────┼────────────┤\n",
       "│ Mantissa bits   │ bits[6:16]              │ 0101110000 │\n",
       "│ Mantissa        │ to_int(bits[6:16])      │ 368        │\n",
       "│ Mantissa Factor │ 1 + mantissa / 2 ** 10  │ 1.359375   │\n",
       "├─────────────────┼─────────────────────────┼────────────┤\n",
       "│ Exponent bits   │ bits[1:6]               │ 10000      │\n",
       "│ Exponent        │ to_int(bits[1:6])       │ 16         │\n",
       "│ Resulting Power │ exponent - 15           │ 1          │\n",
       "│ Exponent Factor │ 2 ** resulting_power    │ 2          │\n",
       "├─────────────────┼─────────────────────────┼────────────┤\n",
       "│ Result          │ 1 * 1.359375 * 2        │ <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">2.71875</span>    │\n",
       "└─────────────────┴─────────────────────────┴────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                         Float16                          \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mDescript       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mEqn                    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ Sign bit        │ bits[0]                 │ 0          │\n",
       "├─────────────────┼─────────────────────────┼────────────┤\n",
       "│ Sign            │ (-1) ** to_int(bits[0]) │ 1          │\n",
       "├─────────────────┼─────────────────────────┼────────────┤\n",
       "│ Mantissa bits   │ bits[6:16]              │ 0101110000 │\n",
       "│ Mantissa        │ to_int(bits[6:16])      │ 368        │\n",
       "│ Mantissa Factor │ 1 + mantissa / 2 ** 10  │ 1.359375   │\n",
       "├─────────────────┼─────────────────────────┼────────────┤\n",
       "│ Exponent bits   │ bits[1:6]               │ 10000      │\n",
       "│ Exponent        │ to_int(bits[1:6])       │ 16         │\n",
       "│ Resulting Power │ exponent - 15           │ 1          │\n",
       "│ Exponent Factor │ 2 ** resulting_power    │ 2          │\n",
       "├─────────────────┼─────────────────────────┼────────────┤\n",
       "│ Result          │ 1 * 1.359375 * 2        │ \u001b[1;34m2.71875\u001b[0m    │\n",
       "└─────────────────┴─────────────────────────┴────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.71875"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = math.e\n",
    "\n",
    "float16bits  = get_raw_bits(torch.tensor(target, dtype=torch.float16),  16)\n",
    "float32bits  = get_raw_bits(torch.tensor(target, dtype=torch.float32),  32)\n",
    "bfloat16bits = get_raw_bits(torch.tensor(target, dtype=torch.bfloat16), 16)\n",
    "\n",
    "float32(float32bits)\n",
    "bfloat16(bfloat16bits)\n",
    "float16(float16bits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                    Float32                                     </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Descript              </span>┃<span style=\"font-weight: bold\"> Eqn                        </span>┃<span style=\"font-weight: bold\"> Value                   </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Sign bit              │ bits[0]                    │ 0                       │\n",
       "├───────────────────────┼────────────────────────────┼─────────────────────────┤\n",
       "│ Sign                  │ (-1) ** (bits[0])          │ 1                       │\n",
       "│ Mantissa bits         │ bits[9:32]                 │ 10010010000111111011011 │\n",
       "│ Mantissa              │ to_int(bits[9:32])         │ 4788187                 │\n",
       "│ Mantissa Multiplier   │ 1 + mantissa / 2 ** 23     │ 1.5707963705062866      │\n",
       "├───────────────────────┼────────────────────────────┼─────────────────────────┤\n",
       "│ Exponent bits         │ bits[1:9]                  │ 10000000                │\n",
       "│ Exponent              │ to_int(bits[1:9])          │ 128                     │\n",
       "│ Exponentiation factor │ 2 ** resulting_power       │ 2                       │\n",
       "│ Resulting Power       │ exponent - 127             │ 1                       │\n",
       "├───────────────────────┼────────────────────────────┼─────────────────────────┤\n",
       "│ Result                │ 1 * 1.5707963705062866 * 2 │ <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">3.1415927410125732</span>      │\n",
       "└───────────────────────┴────────────────────────────┴─────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                    Float32                                     \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mDescript             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mEqn                       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                  \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Sign bit              │ bits[0]                    │ 0                       │\n",
       "├───────────────────────┼────────────────────────────┼─────────────────────────┤\n",
       "│ Sign                  │ (-1) ** (bits[0])          │ 1                       │\n",
       "│ Mantissa bits         │ bits[9:32]                 │ 10010010000111111011011 │\n",
       "│ Mantissa              │ to_int(bits[9:32])         │ 4788187                 │\n",
       "│ Mantissa Multiplier   │ 1 + mantissa / 2 ** 23     │ 1.5707963705062866      │\n",
       "├───────────────────────┼────────────────────────────┼─────────────────────────┤\n",
       "│ Exponent bits         │ bits[1:9]                  │ 10000000                │\n",
       "│ Exponent              │ to_int(bits[1:9])          │ 128                     │\n",
       "│ Exponentiation factor │ 2 ** resulting_power       │ 2                       │\n",
       "│ Resulting Power       │ exponent - 127             │ 1                       │\n",
       "├───────────────────────┼────────────────────────────┼─────────────────────────┤\n",
       "│ Result                │ 1 * 1.5707963705062866 * 2 │ \u001b[1;34m3.1415927410125732\u001b[0m      │\n",
       "└───────────────────────┴────────────────────────────┴─────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                          BFloat16                           </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Descript            </span>┃<span style=\"font-weight: bold\"> Eqn                     </span>┃<span style=\"font-weight: bold\"> Value     </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━┩\n",
       "│ Sign bits           │ bits[0]                 │ 0         │\n",
       "├─────────────────────┼─────────────────────────┼───────────┤\n",
       "│ Sign                │ (-1) ** to_int(bits[0]) │ 1         │\n",
       "├─────────────────────┼─────────────────────────┼───────────┤\n",
       "│ Mantissa bits       │ bits[9:16]              │ 1001001   │\n",
       "│ Mantissa            │ to_int(bits[9:16])      │ 73        │\n",
       "│ Mantissa Multiplier │ 1 + mantissa / 2 ** 7   │ 1.5703125 │\n",
       "├─────────────────────┼─────────────────────────┼───────────┤\n",
       "│ Exponent bits       │ bits[1:9]               │ 10000000  │\n",
       "│ Exponent            │ to_int(bits[1:9])       │ 128       │\n",
       "│ Resulting Power     │ exponent - 127          │ 1         │\n",
       "│ Exponent Factor     │ 2 ** resulting_power    │ 2         │\n",
       "├─────────────────────┼─────────────────────────┼───────────┤\n",
       "│ Result              │ 1 * 1.5703125 * 2       │ <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">3.140625</span>  │\n",
       "└─────────────────────┴─────────────────────────┴───────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                          BFloat16                           \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mDescript           \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mEqn                    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue    \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━┩\n",
       "│ Sign bits           │ bits[0]                 │ 0         │\n",
       "├─────────────────────┼─────────────────────────┼───────────┤\n",
       "│ Sign                │ (-1) ** to_int(bits[0]) │ 1         │\n",
       "├─────────────────────┼─────────────────────────┼───────────┤\n",
       "│ Mantissa bits       │ bits[9:16]              │ 1001001   │\n",
       "│ Mantissa            │ to_int(bits[9:16])      │ 73        │\n",
       "│ Mantissa Multiplier │ 1 + mantissa / 2 ** 7   │ 1.5703125 │\n",
       "├─────────────────────┼─────────────────────────┼───────────┤\n",
       "│ Exponent bits       │ bits[1:9]               │ 10000000  │\n",
       "│ Exponent            │ to_int(bits[1:9])       │ 128       │\n",
       "│ Resulting Power     │ exponent - 127          │ 1         │\n",
       "│ Exponent Factor     │ 2 ** resulting_power    │ 2         │\n",
       "├─────────────────────┼─────────────────────────┼───────────┤\n",
       "│ Result              │ 1 * 1.5703125 * 2       │ \u001b[1;34m3.140625\u001b[0m  │\n",
       "└─────────────────────┴─────────────────────────┴───────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                         Float16                          </span>\n",
       "┏━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Descript        </span>┃<span style=\"font-weight: bold\"> Eqn                     </span>┃<span style=\"font-weight: bold\"> Value      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ Sign bit        │ bits[0]                 │ 0          │\n",
       "├─────────────────┼─────────────────────────┼────────────┤\n",
       "│ Sign            │ (-1) ** to_int(bits[0]) │ 1          │\n",
       "├─────────────────┼─────────────────────────┼────────────┤\n",
       "│ Mantissa bits   │ bits[6:16]              │ 1001001000 │\n",
       "│ Mantissa        │ to_int(bits[6:16])      │ 584        │\n",
       "│ Mantissa Factor │ 1 + mantissa / 2 ** 10  │ 1.5703125  │\n",
       "├─────────────────┼─────────────────────────┼────────────┤\n",
       "│ Exponent bits   │ bits[1:6]               │ 10000      │\n",
       "│ Exponent        │ to_int(bits[1:6])       │ 16         │\n",
       "│ Resulting Power │ exponent - 15           │ 1          │\n",
       "│ Exponent Factor │ 2 ** resulting_power    │ 2          │\n",
       "├─────────────────┼─────────────────────────┼────────────┤\n",
       "│ Result          │ 1 * 1.5703125 * 2       │ <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">3.140625</span>   │\n",
       "└─────────────────┴─────────────────────────┴────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                         Float16                          \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mDescript       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mEqn                    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ Sign bit        │ bits[0]                 │ 0          │\n",
       "├─────────────────┼─────────────────────────┼────────────┤\n",
       "│ Sign            │ (-1) ** to_int(bits[0]) │ 1          │\n",
       "├─────────────────┼─────────────────────────┼────────────┤\n",
       "│ Mantissa bits   │ bits[6:16]              │ 1001001000 │\n",
       "│ Mantissa        │ to_int(bits[6:16])      │ 584        │\n",
       "│ Mantissa Factor │ 1 + mantissa / 2 ** 10  │ 1.5703125  │\n",
       "├─────────────────┼─────────────────────────┼────────────┤\n",
       "│ Exponent bits   │ bits[1:6]               │ 10000      │\n",
       "│ Exponent        │ to_int(bits[1:6])       │ 16         │\n",
       "│ Resulting Power │ exponent - 15           │ 1          │\n",
       "│ Exponent Factor │ 2 ** resulting_power    │ 2          │\n",
       "├─────────────────┼─────────────────────────┼────────────┤\n",
       "│ Result          │ 1 * 1.5703125 * 2       │ \u001b[1;34m3.140625\u001b[0m   │\n",
       "└─────────────────┴─────────────────────────┴────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.140625"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = math.pi\n",
    "\n",
    "float16bits  = get_raw_bits(torch.tensor(target, dtype=torch.float16),  16)\n",
    "float32bits  = get_raw_bits(torch.tensor(target, dtype=torch.float32),  32)\n",
    "bfloat16bits = get_raw_bits(torch.tensor(target, dtype=torch.bfloat16), 16)\n",
    "\n",
    "float32(float32bits)\n",
    "bfloat16(bfloat16bits)\n",
    "float16(float16bits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to launch a job with multiple nodes on the Mila cluster\n",
    "\n",
    "The main idea is that `srun` launches the same process multiple times, scaling on a single node or on multiple nodes.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "Substituting `$NUMBER_OF_TASKS_PER_NODE` with the number of GPUs on per node, the following flag dictates how many parallel processes will be launched on each node:\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "`--ntasks-per-node=$NUMBER_OF_TASKS_PER_NODE`\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "As such, to lauch jobs, do one of the following, substituting `$NUMBER_OF_GPUS_PER_NODE` with the number of GPUs you want to use per node.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "To launch jobs for later, \n",
    "\n",
    "&nbsp;\n",
    "\n",
    "```bash\n",
    "sbatch script.sh --gres=gpu:$NUMBER_OF_GPUS_PER_NODE --mem=16G --cpus-per-task=6 --ntasks-per-node=$NUMBER_OF_GPUS_PER_NODE\n",
    "```\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "\n",
    "to launch jobs right now:\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "```bash\n",
    "salloc --gres=gpu:$NUMBER_OF_GPUS_PER_NODE --mem=16G --cpus-per-task=6 --ntasks-per-node=$NUMBER_OF_GPUS_PER_NODE\n",
    "```\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "\n",
    "Then, in your `script.sh` or in your interactive shell, launch your job with `srun`:\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "```bash\n",
    "srun python script.py\n",
    "```\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "\n",
    "`srun` will launch the same process multiple times, multiple times per node, and scaling to multiple nodes.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "\n",
    "Each process will be have multiple environment variables set. This allows you to code different behavior for each process.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- `SLURM_PROCID`, for example, is the global id of the process.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- `SLURM_LOCALID` is the id of the process on the node.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- `SLURM_NTASKS_PER_NODE` is the number of processes per node.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "The following command will let you explore what environment variables are set. `env` prints all the environment variables:\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "```bash\n",
    "srun bash -c 'env | grep SLURM'\n",
    "```\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "\n",
    "### Multi Node Training With Pytorch Lightning\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "After launching your script with `srun`, you just have to have the following in your trainer code in Pytorch Lightning:\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "![Getting Started](lightning_multi_node.png)\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "Behind the scenes, Pytorch Lightning will automatically use the SLURM environment variables to launch a server on the first node. It will also use the environment variables to connect to the server on that node, from the other servers, to synchronize the training.\n",
    "\n",
    "Pytorch Lightning will also automatically use a distributed sampler, so each process will only train on a subset of the data.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "More information here: https://pytorch-lightning.readthedocs.io/en/stable/clouds/cluster_advanced.html#run-on-a-slurm-managed-cluster\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "You can set-up something similar on raw Pytorch with `torch.distributed.launch`, but it is more complicated. See an example here https://gist.github.com/TengdaHan/1dd10d335c7ca6f13810fff41e809904\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4373dfae08f86e1cbb30276a64388ceb0cca01fb3413c04c67d6728de3721b03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
